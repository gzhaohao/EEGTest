{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gzhaohao/EEGTest/blob/main/bcieeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **获取数据并解压**"
      ],
      "metadata": {
        "id": "Y_5mZ-dPoeWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A02T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A04T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A05T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A06T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A07T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A08T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A09T.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A02E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A04E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A05E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A06E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A07E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A08E.mat\n",
        "!wget https://bnci-horizon-2020.eu/database/data-sets/001-2014/A09E.mat\n",
        "!unzip -q BCICIV_2a_gdf.zip\n",
        "!rm BCICIV_2a_gdf.zip"
      ],
      "metadata": {
        "id": "qo7_FvGtnYgE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48fbc207-d4b3-4df7-adc3-72bef2d61e14"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-08 10:18:52--  https://www.bbci.de/competition/download/competition_iv/BCICIV_2a_gdf.zip\n",
            "Resolving www.bbci.de (www.bbci.de)... 141.23.71.83\n",
            "Connecting to www.bbci.de (www.bbci.de)|141.23.71.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439968864 (420M) [application/zip]\n",
            "Saving to: ‘BCICIV_2a_gdf.zip’\n",
            "\n",
            "BCICIV_2a_gdf.zip   100%[===================>] 419.59M  19.3MB/s    in 24s     \n",
            "\n",
            "2025-11-08 10:19:17 (17.8 MB/s) - ‘BCICIV_2a_gdf.zip’ saved [439968864/439968864]\n",
            "\n",
            "--2025-11-08 10:19:17--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A01T.mat [following]\n",
            "--2025-11-08 10:19:18--  https://lampx.tugraz.at/~bci/database/001-2014/A01T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42806453 (41M)\n",
            "Saving to: ‘A01T.mat’\n",
            "\n",
            "A01T.mat            100%[===================>]  40.82M  10.7MB/s    in 4.9s    \n",
            "\n",
            "2025-11-08 10:19:25 (8.37 MB/s) - ‘A01T.mat’ saved [42806453/42806453]\n",
            "\n",
            "--2025-11-08 10:19:25--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A02T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A02T.mat [following]\n",
            "--2025-11-08 10:19:25--  https://lampx.tugraz.at/~bci/database/001-2014/A02T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43068077 (41M)\n",
            "Saving to: ‘A02T.mat’\n",
            "\n",
            "A02T.mat            100%[===================>]  41.07M  11.7MB/s    in 3.5s    \n",
            "\n",
            "2025-11-08 10:19:30 (11.7 MB/s) - ‘A02T.mat’ saved [43068077/43068077]\n",
            "\n",
            "--2025-11-08 10:19:30--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A03T.mat [following]\n",
            "--2025-11-08 10:19:31--  https://lampx.tugraz.at/~bci/database/001-2014/A03T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44057065 (42M)\n",
            "Saving to: ‘A03T.mat’\n",
            "\n",
            "A03T.mat            100%[===================>]  42.02M  10.8MB/s    in 4.9s    \n",
            "\n",
            "2025-11-08 10:19:36 (8.50 MB/s) - ‘A03T.mat’ saved [44057065/44057065]\n",
            "\n",
            "--2025-11-08 10:19:36--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A04T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A04T.mat [following]\n",
            "--2025-11-08 10:19:37--  https://lampx.tugraz.at/~bci/database/001-2014/A04T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37150377 (35M)\n",
            "Saving to: ‘A04T.mat’\n",
            "\n",
            "A04T.mat            100%[===================>]  35.43M  10.0MB/s    in 4.4s    \n",
            "\n",
            "2025-11-08 10:19:42 (8.11 MB/s) - ‘A04T.mat’ saved [37150377/37150377]\n",
            "\n",
            "--2025-11-08 10:19:42--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A05T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A05T.mat [following]\n",
            "--2025-11-08 10:19:43--  https://lampx.tugraz.at/~bci/database/001-2014/A05T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42452392 (40M)\n",
            "Saving to: ‘A05T.mat’\n",
            "\n",
            "A05T.mat            100%[===================>]  40.49M  10.9MB/s    in 4.8s    \n",
            "\n",
            "2025-11-08 10:19:48 (8.50 MB/s) - ‘A05T.mat’ saved [42452392/42452392]\n",
            "\n",
            "--2025-11-08 10:19:48--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A06T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A06T.mat [following]\n",
            "--2025-11-08 10:19:49--  https://lampx.tugraz.at/~bci/database/001-2014/A06T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44581256 (43M)\n",
            "Saving to: ‘A06T.mat’\n",
            "\n",
            "A06T.mat            100%[===================>]  42.52M  11.0MB/s    in 4.9s    \n",
            "\n",
            "2025-11-08 10:19:55 (8.60 MB/s) - ‘A06T.mat’ saved [44581256/44581256]\n",
            "\n",
            "--2025-11-08 10:19:56--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A07T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A07T.mat [following]\n",
            "--2025-11-08 10:19:56--  https://lampx.tugraz.at/~bci/database/001-2014/A07T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42809746 (41M)\n",
            "Saving to: ‘A07T.mat’\n",
            "\n",
            "A07T.mat            100%[===================>]  40.83M  10.4MB/s    in 5.0s    \n",
            "\n",
            "2025-11-08 10:20:02 (8.23 MB/s) - ‘A07T.mat’ saved [42809746/42809746]\n",
            "\n",
            "--2025-11-08 10:20:02--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A08T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A08T.mat [following]\n",
            "--2025-11-08 10:20:03--  https://lampx.tugraz.at/~bci/database/001-2014/A08T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45032065 (43M)\n",
            "Saving to: ‘A08T.mat’\n",
            "\n",
            "A08T.mat            100%[===================>]  42.95M  11.0MB/s    in 5.0s    \n",
            "\n",
            "2025-11-08 10:20:08 (8.64 MB/s) - ‘A08T.mat’ saved [45032065/45032065]\n",
            "\n",
            "--2025-11-08 10:20:08--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A09T.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A09T.mat [following]\n",
            "--2025-11-08 10:20:09--  https://lampx.tugraz.at/~bci/database/001-2014/A09T.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44785478 (43M)\n",
            "Saving to: ‘A09T.mat’\n",
            "\n",
            "A09T.mat            100%[===================>]  42.71M  10.3MB/s    in 5.2s    \n",
            "\n",
            "2025-11-08 10:20:15 (8.24 MB/s) - ‘A09T.mat’ saved [44785478/44785478]\n",
            "\n",
            "--2025-11-08 10:20:15--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A01E.mat [following]\n",
            "--2025-11-08 10:20:16--  https://lampx.tugraz.at/~bci/database/001-2014/A01E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43772146 (42M)\n",
            "Saving to: ‘A01E.mat’\n",
            "\n",
            "A01E.mat            100%[===================>]  41.74M  8.52MB/s    in 6.1s    \n",
            "\n",
            "2025-11-08 10:20:23 (6.89 MB/s) - ‘A01E.mat’ saved [43772146/43772146]\n",
            "\n",
            "--2025-11-08 10:20:23--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A02E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A02E.mat [following]\n",
            "--2025-11-08 10:20:23--  https://lampx.tugraz.at/~bci/database/001-2014/A02E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44218409 (42M)\n",
            "Saving to: ‘A02E.mat’\n",
            "\n",
            "A02E.mat            100%[===================>]  42.17M  11.5MB/s    in 4.8s    \n",
            "\n",
            "2025-11-08 10:20:30 (8.87 MB/s) - ‘A02E.mat’ saved [44218409/44218409]\n",
            "\n",
            "--2025-11-08 10:20:30--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A03E.mat [following]\n",
            "--2025-11-08 10:20:31--  https://lampx.tugraz.at/~bci/database/001-2014/A03E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42316292 (40M)\n",
            "Saving to: ‘A03E.mat’\n",
            "\n",
            "A03E.mat            100%[===================>]  40.36M  9.76MB/s    in 5.3s    \n",
            "\n",
            "2025-11-08 10:20:37 (7.64 MB/s) - ‘A03E.mat’ saved [42316292/42316292]\n",
            "\n",
            "--2025-11-08 10:20:37--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A04E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A04E.mat [following]\n",
            "--2025-11-08 10:20:38--  https://lampx.tugraz.at/~bci/database/001-2014/A04E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41730824 (40M)\n",
            "Saving to: ‘A04E.mat’\n",
            "\n",
            "A04E.mat            100%[===================>]  39.80M  9.82MB/s    in 5.2s    \n",
            "\n",
            "2025-11-08 10:20:44 (7.62 MB/s) - ‘A04E.mat’ saved [41730824/41730824]\n",
            "\n",
            "--2025-11-08 10:20:44--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A05E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A05E.mat [following]\n",
            "--2025-11-08 10:20:45--  https://lampx.tugraz.at/~bci/database/001-2014/A05E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44392496 (42M)\n",
            "Saving to: ‘A05E.mat’\n",
            "\n",
            "A05E.mat            100%[===================>]  42.34M  10.7MB/s    in 5.1s    \n",
            "\n",
            "2025-11-08 10:20:50 (8.31 MB/s) - ‘A05E.mat’ saved [44392496/44392496]\n",
            "\n",
            "--2025-11-08 10:20:51--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A06E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A06E.mat [following]\n",
            "--2025-11-08 10:20:51--  https://lampx.tugraz.at/~bci/database/001-2014/A06E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43395510 (41M)\n",
            "Saving to: ‘A06E.mat’\n",
            "\n",
            "A06E.mat            100%[===================>]  41.38M  6.08MB/s    in 6.9s    \n",
            "\n",
            "2025-11-08 10:20:59 (6.02 MB/s) - ‘A06E.mat’ saved [43395510/43395510]\n",
            "\n",
            "--2025-11-08 10:20:59--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A07E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A07E.mat [following]\n",
            "--2025-11-08 10:21:00--  https://lampx.tugraz.at/~bci/database/001-2014/A07E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42242294 (40M)\n",
            "Saving to: ‘A07E.mat’\n",
            "\n",
            "A07E.mat            100%[===================>]  40.29M  9.76MB/s    in 5.4s    \n",
            "\n",
            "2025-11-08 10:21:06 (7.49 MB/s) - ‘A07E.mat’ saved [42242294/42242294]\n",
            "\n",
            "--2025-11-08 10:21:06--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A08E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A08E.mat [following]\n",
            "--2025-11-08 10:21:07--  https://lampx.tugraz.at/~bci/database/001-2014/A08E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46282127 (44M)\n",
            "Saving to: ‘A08E.mat’\n",
            "\n",
            "A08E.mat            100%[===================>]  44.14M  10.2MB/s    in 5.7s    \n",
            "\n",
            "2025-11-08 10:21:13 (7.78 MB/s) - ‘A08E.mat’ saved [46282127/46282127]\n",
            "\n",
            "--2025-11-08 10:21:13--  https://bnci-horizon-2020.eu/database/data-sets/001-2014/A09E.mat\n",
            "Resolving bnci-horizon-2020.eu (bnci-horizon-2020.eu)... 91.227.205.222, 2a03:f80:ad15:91:227:205:222:1\n",
            "Connecting to bnci-horizon-2020.eu (bnci-horizon-2020.eu)|91.227.205.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://lampx.tugraz.at/~bci/database/001-2014/A09E.mat [following]\n",
            "--2025-11-08 10:21:14--  https://lampx.tugraz.at/~bci/database/001-2014/A09E.mat\n",
            "Resolving lampx.tugraz.at (lampx.tugraz.at)... 129.27.124.233\n",
            "Connecting to lampx.tugraz.at (lampx.tugraz.at)|129.27.124.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44780912 (43M)\n",
            "Saving to: ‘A09E.mat’\n",
            "\n",
            "A09E.mat            100%[===================>]  42.71M  10.3MB/s    in 5.5s    \n",
            "\n",
            "2025-11-08 10:21:20 (7.83 MB/s) - ‘A09E.mat’ saved [44780912/44780912]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **挂载Google云盘**"
      ],
      "metadata": {
        "id": "umVk4TmVf_bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KdxvkPcOfVlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aff8d4b-2422-4439-f33e-b73151db8c6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **安装python依赖**"
      ],
      "metadata": {
        "id": "_xHR_RP8AcyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "!pip install ipdb"
      ],
      "metadata": {
        "id": "A0GfDYvmAj_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1575aa0b-7961-45e1-dd6b-ed378c30971a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.10.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.10.5)\n",
            "Downloading mne-1.10.2-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.10.2\n",
            "Collecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.12/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.14)\n",
            "Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.13 jedi-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **model.py**"
      ],
      "metadata": {
        "id": "cCoqY8yp31eh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez0GDqI10HEy"
      },
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "# 按照论文创建EEGNet\n",
        "class EEGNet(nn.Module):\n",
        "    def __init__(self, n_classes=4, channels=22, samples=1000,\n",
        "                 dropout_rate=0.5, kernel_length1=64, kernel_length2=16,\n",
        "                 f1=8, d=2, f2=16):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.f1 = f1\n",
        "        self.f2 = f2\n",
        "        self.d = d\n",
        "        self.samples = samples\n",
        "        self.n_classes = n_classes\n",
        "        self.channels = channels\n",
        "        self.kernel_length1 = kernel_length1\n",
        "        self.kernel_length2 = kernel_length2\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        block1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=self.f1,\n",
        "                kernel_size=(1, self.kernel_length1),\n",
        "                stride=1,\n",
        "                padding=(0, self.kernel_length1//2),\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=self.f1)\n",
        "        )\n",
        "\n",
        "        block2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.f1,\n",
        "                out_channels=self.f1*self.d,\n",
        "                kernel_size=(self.channels, 1),\n",
        "                groups=self.f1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=self.f1*self.d),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(\n",
        "                kernel_size=(1, 4),\n",
        "                stride=4\n",
        "            ),\n",
        "            nn.Dropout(p=self.dropout_rate)\n",
        "        )\n",
        "\n",
        "        block3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.f2,\n",
        "                out_channels=self.f2,\n",
        "                kernel_size=(1, self.kernel_length2),\n",
        "                stride=1,\n",
        "                padding=(0, self.kernel_length2//2),\n",
        "                groups=self.f1*self.d,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.Conv2d(\n",
        "                in_channels=self.f1*self.d,\n",
        "                out_channels=self.f2,\n",
        "                kernel_size=(1, 1),\n",
        "                stride=1,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(num_features=self.f2),\n",
        "            nn.ELU(),\n",
        "            nn.AvgPool2d(\n",
        "                kernel_size=(1, 8),\n",
        "                stride=8\n",
        "            ),\n",
        "            nn.Dropout(p=self.dropout_rate)\n",
        "        )\n",
        "\n",
        "        self.EEGNetLayer = nn.Sequential(block1, block2, block3)\n",
        "\n",
        "        self.ClassifierBlock = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                in_features=self.f2*round(round(self.samples//4)//8),\n",
        "                out_features=self.n_classes,\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) != 4:\n",
        "            x = torch.unsqueeze(x, dim=1)\n",
        "        x = self.EEGNetLayer(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.ClassifierBlock(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# 模型结构可视化\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = EEGNet().to(device)\n",
        "    print(summary(model, input_size=(1, 22, 1000)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **model_train.py**"
      ],
      "metadata": {
        "id": "FEh-At_B4JEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的库\n",
        "import mne\n",
        "import scipy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import copy\n",
        "import time\n",
        "#from model import EEGNet\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 1、创建必要的本地目录，用于保存数据\n",
        "if not os.path.exists('2a_train_pre'):\n",
        "    os.makedirs('2a_train_pre')\n",
        "\n",
        "# 2、原始数据读取和通道重命名\n",
        "data_path = ['A0'+str(i)+'T' for i in range(1, 10)]\n",
        "raw = [mne.io.read_raw_gdf(input_fname='./'+path+'.gdf',\n",
        "                           stim_channel=\"auto\",\n",
        "                           preload=True,\n",
        "                           verbose=\"error\") for path in data_path]\n",
        "\n",
        "for i in range(len(raw)):\n",
        "    raw[i].rename_channels({'EEG-Fz': 'Fz', 'EEG-0': 'FC3', 'EEG-1': 'FC1', 'EEG-2': 'FCz', 'EEG-3': 'FC2',\n",
        "                            'EEG-4': 'FC4', 'EEG-5': 'C5', 'EEG-C3': 'C3', 'EEG-6': 'C1', 'EEG-Cz': 'Cz',\n",
        "                            'EEG-7': 'C2', 'EEG-C4': 'C4', 'EEG-8': 'C6', 'EEG-9': 'CP3', 'EEG-10': 'CP1',\n",
        "                            'EEG-11': 'CPz', 'EEG-12': 'CP2', 'EEG-13': 'CP4', 'EEG-14': 'P1', 'EEG-15': 'Pz',\n",
        "                            'EEG-16': 'P2', 'EEG-Pz': 'POz'})\n",
        "\n",
        "# 3、提取MI时间，完成坏值清洗，并封装\n",
        "events = []\n",
        "event_ids = []\n",
        "for i in range(len(raw)):\n",
        "    event_to_id = dict({'769': 7, '770': 8, '771': 9, '772': 10})\n",
        "    if i == 3:\n",
        "        event_to_id = dict({'769': 5, '770': 6, '771': 7, '772': 8})\n",
        "        event, _ = mne.events_from_annotations(raw[i], verbose=False)\n",
        "        events.append(event)\n",
        "        ids = np.unique(events[i][:, 2])\n",
        "        event_id = {k: v for k, v in event_to_id.items() if v in ids}\n",
        "        event_ids.append(event_id)\n",
        "        raw[i].load_data()\n",
        "        data = raw[i].get_data()\n",
        "    else:\n",
        "        event, _ = mne.events_from_annotations(raw[i], verbose=False)\n",
        "        events.append(event)\n",
        "        ids = np.unique(events[i][:, 2])\n",
        "        event_id = {k: v for k, v in event_to_id.items() if v in ids}\n",
        "        event_ids.append(event_id)\n",
        "        raw[i].load_data()\n",
        "        data = raw[i].get_data()\n",
        "    for i_chan in range(data.shape[0]):\n",
        "        chan = data[i_chan]\n",
        "        data[i_chan] = np.where(chan == np.min(chan), np.nan, chan)\n",
        "        mask = np.isnan(data[i_chan])\n",
        "        chan_mean = np.nanmean(data[i_chan])\n",
        "        data[i_chan, mask] = chan_mean\n",
        "    raw[i] = mne.io.RawArray(data, raw[i].info, verbose=\"error\")\n",
        "\n",
        "# 4、切段、去EOG、做标准化，封存数据为npz\n",
        "tmin, tmax = 0, 4\n",
        "for i in range(len(raw)):\n",
        "    epochs = mne.Epochs(raw[i], events[i], event_ids[i], tmin, tmax, proj=False, baseline=None, preload=True)\n",
        "\n",
        "    exclude = [\"EOG-left\", \"EOG-central\", \"EOG-right\"]\n",
        "    epochs.drop_channels(exclude)\n",
        "\n",
        "    labels_file = scipy.io.loadmat('./'+data_path[i]+'.mat')\n",
        "\n",
        "    # 打印所有键以便调试\n",
        "    print(f\"MAT file keys for {data_path[i]}: {list(labels_file.keys())}\")\n",
        "\n",
        "    # 新的标签提取方法 - 从data结构体的y字段提取\n",
        "    if 'data' in labels_file:\n",
        "        data_struct = labels_file['data']\n",
        "        print(f\"Data structure shape: {data_struct.shape}\")\n",
        "\n",
        "        # 提取所有trial的标签\n",
        "        all_labels = []\n",
        "        for trial_idx in range(data_struct.shape[1]):\n",
        "            trial_data = data_struct[0, trial_idx]\n",
        "            labels = trial_data['y'][0, 0]  # 提取y字段\n",
        "\n",
        "            if labels.size > 0:  # 只处理有标签的trial\n",
        "                trial_labels = labels.flatten().tolist()\n",
        "                all_labels.extend(trial_labels)\n",
        "                print(f\"Trial {trial_idx+1}: 标签数量 {len(trial_labels)}\")\n",
        "            else:\n",
        "                print(f\"Trial {trial_idx+1}: 无标签\")\n",
        "\n",
        "        labels = np.array(all_labels)\n",
        "        print(f\"提取的总标签数量: {len(labels)}, 唯一标签: {np.unique(labels)}\")\n",
        "\n",
        "        # 显示类别对应关系（用于验证）\n",
        "        if len(all_labels) > 0:\n",
        "            classes = data_struct[0, 0]['classes'][0, 0][0]\n",
        "            print(\"类别对应关系:\")\n",
        "            for class_idx, class_name in enumerate(classes):\n",
        "                print(f\"  标签 {class_idx+1}: {class_name[0]}\")\n",
        "\n",
        "    else:\n",
        "        # 备用方法：使用事件信息生成标签\n",
        "        print(\"使用事件信息生成标签\")\n",
        "        labels = events[i][:, 2]\n",
        "        label_mapping = {7: 1, 8: 2, 9: 3, 10: 4}\n",
        "        if i == 3:  # 特殊处理第4个文件\n",
        "            label_mapping = {5: 1, 6: 2, 7: 3, 8: 4}\n",
        "        labels = np.array([label_mapping.get(event_id, 0) for event_id in labels])\n",
        "        labels = labels[labels != 0]  # 移除无效标签\n",
        "\n",
        "    print(f\"最终标签形状: {labels.shape}, 唯一标签: {np.unique(labels)}\")\n",
        "\n",
        "    epochs_data = epochs.get_data(copy=True)[:, :, :-1]\n",
        "\n",
        "    # 确保标签数量与数据样本数量匹配\n",
        "    n_samples = epochs_data.shape[0]\n",
        "    if len(labels) != n_samples:\n",
        "        print(f\"警告: 标签数量 ({len(labels)}) 与数据样本数量 ({n_samples}) 不匹配\")\n",
        "        # 截取或调整标签以匹配数据数量\n",
        "        min_length = min(len(labels), n_samples)\n",
        "        labels = labels[:min_length]\n",
        "        epochs_data = epochs_data[:min_length]\n",
        "        print(f\"调整后: 标签数量 {len(labels)}, 数据样本数量 {epochs_data.shape[0]}\")\n",
        "\n",
        "    n_channels, n_timepoints = epochs_data.shape[1], epochs_data.shape[2]\n",
        "    epochs_data_flat = epochs_data.reshape(n_samples, -1)\n",
        "\n",
        "    scaler = StandardScaler().fit(epochs_data_flat)\n",
        "    data_scaled = scaler.transform(epochs_data_flat)\n",
        "\n",
        "    data_scaled = data_scaled.reshape(n_samples, n_channels, n_timepoints)\n",
        "\n",
        "    np.savez('2a_train_pre/'+data_path[i]+'.npz', data=data_scaled, label=labels)\n",
        "# 5、创建训练集和验证集数据加载器\n",
        "def create_simple_dataloaders():\n",
        "    # 加载数据\n",
        "    x_train, y_train = [], []\n",
        "    for i in range(1, 10):\n",
        "        train_data = np.load(f'2a_train_pre/A0{i}T.npz')\n",
        "        x_train.append(train_data['data'])\n",
        "        y_train.append(train_data['label'])\n",
        "\n",
        "    # 合并数据\n",
        "    x_train = np.concatenate(x_train)\n",
        "    y_train = np.concatenate(y_train)\n",
        "\n",
        "    # 转换为PyTorch张量\n",
        "    x_train = torch.FloatTensor(x_train).unsqueeze(1)\n",
        "    y_train = torch.LongTensor(y_train - 1)\n",
        "\n",
        "    # 创建完整数据集\n",
        "    full_dataset = TensorDataset(x_train, y_train)\n",
        "\n",
        "    # 计算训练集和验证集大小\n",
        "    dataset_size = len(full_dataset)\n",
        "    val_size = int(dataset_size * 0.2)\n",
        "    train_size = dataset_size - val_size\n",
        "\n",
        "    # 划分训练集和验证集\n",
        "    train_data, val_data = random_split(\n",
        "        full_dataset,\n",
        "        [train_size, val_size]\n",
        "    )\n",
        "\n",
        "    # 创建DataLoader\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "# 6、训练模型\n",
        "def train_model_process(model, train_loader, val_loader, num_epochs):\n",
        "    # 设定训练所用到的设备，有GPU用GPU没有GPU用CPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # 使用Adam优化器，学习率为0.001\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    # 损失函数为交叉熵函数\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # 将模型放入到训练设备中\n",
        "    model = model.to(device)\n",
        "    # 复制当前模型的参数\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # 初始化参数\n",
        "    best_acc = 0.0\n",
        "    train_loss_all = []\n",
        "    val_loss_all = []\n",
        "    train_acc_all = []\n",
        "    val_acc_all = []\n",
        "    since = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch, num_epochs-1))\n",
        "        print(\"-\"*10)\n",
        "\n",
        "        # 初始化参数\n",
        "        train_loss = 0.0\n",
        "        train_corrects = 0\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        train_num = 0\n",
        "        val_num = 0\n",
        "\n",
        "        # 对每一个batch训练和计算\n",
        "        for step, (b_x, b_y) in enumerate(train_loader):\n",
        "            # 将特征放入到训练设备中\n",
        "            b_x = b_x.to(device)\n",
        "            # 将标签放入到训练设备中\n",
        "            b_y = b_y.to(device)\n",
        "            # 设置模型为训练模式\n",
        "            model.train()\n",
        "\n",
        "            # 前向传播过程，输入为一个batch，输出为一个batch中对应的预测\n",
        "            output = model(b_x)\n",
        "            # 查找每一行中最大值对应的行标\n",
        "            pre_lab = torch.argmax(output, dim=1)\n",
        "            # 计算每一个batch的损失函数\n",
        "            loss = criterion(output, b_y)\n",
        "\n",
        "            # 将梯度初始化为0\n",
        "            optimizer.zero_grad()\n",
        "            # 反向传播计算\n",
        "            loss.backward()\n",
        "            # 根据网络反向传播的梯度信息来更新网络的参数，以起到降低loss函数计算值的作用\n",
        "            optimizer.step()\n",
        "            # 对损失函数进行累加\n",
        "            train_loss += loss.item() * b_x.size(0)\n",
        "            # 如果预测正确，则准确度train_corrects加1\n",
        "            train_corrects += torch.sum(pre_lab == b_y.data)\n",
        "            # 当前用于训练的样本数量\n",
        "            train_num += b_x.size(0)\n",
        "\n",
        "        for step, (b_x, b_y) in enumerate(val_loader):\n",
        "            # 将特征放入到验证设备中\n",
        "            b_x = b_x.to(device)\n",
        "            # 将标签放入到验证设备中\n",
        "            b_y = b_y.to(device)\n",
        "            # 设置模型为评估模式\n",
        "            model.eval()\n",
        "            # 前向传播过程，输入为一个batch，输出为一个batch中对应的预测\n",
        "            output = model(b_x)\n",
        "            # 查找每一行中最大值对应的行标\n",
        "            pre_lab = torch.argmax(output, dim=1)\n",
        "            # 计算每一个batch的损失函数\n",
        "            loss = criterion(output, b_y)\n",
        "\n",
        "            # 对损失函数进行累加\n",
        "            val_loss += loss.item() * b_x.size(0)\n",
        "            # 如果预测正确，则准确度train_corrects加1\n",
        "            val_corrects += torch.sum(pre_lab == b_y.data)\n",
        "            # 当前用于验证的样本数量\n",
        "            val_num += b_x.size(0)\n",
        "\n",
        "        # 计算并保存每一次迭代的loss值和准确率\n",
        "        # 计算并保存训练集的loss值\n",
        "        train_loss_all.append(train_loss / train_num)\n",
        "        # 计算并保存训练集的准确率\n",
        "        train_acc_all.append(train_corrects.double().item() / train_num)\n",
        "\n",
        "        # 计算并保存验证集的loss值\n",
        "        val_loss_all.append(val_loss / val_num)\n",
        "        # 计算并保存验证集的准确率\n",
        "        val_acc_all.append(val_corrects.double().item() / val_num)\n",
        "\n",
        "        print(\"{} train loss:{:.4f} train acc: {:.4f}\".format(epoch, train_loss_all[-1], train_acc_all[-1]))\n",
        "        print(\"{} val loss:{:.4f} val acc: {:.4f}\".format(epoch, val_loss_all[-1], val_acc_all[-1]))\n",
        "\n",
        "        if val_acc_all[-1] > best_acc:\n",
        "            # 保存当前最高准确度\n",
        "            best_acc = val_acc_all[-1]\n",
        "            # 保存当前最高准确度的模型参数\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        # 计算训练和验证的耗时\n",
        "        time_use = time.time() - since\n",
        "        print(\"训练和验证耗费的时间{:.0f}m{:.0f}s\".format(time_use//60, time_use % 60))\n",
        "\n",
        "    # 选择最优参数，保存最优参数的模型\n",
        "    torch.save(best_model_wts, \"best_model.pth\")\n",
        "\n",
        "    train_process = pd.DataFrame(data={\"epoch\": range(num_epochs),\n",
        "\"train_loss_all\": train_loss_all,\n",
        "\"val_loss_all\": val_loss_all,\n",
        "\"train_acc_all\": train_acc_all,\n",
        "\"val_acc_all\": val_acc_all})\n",
        "\n",
        "    return train_process\n",
        "\n",
        "\n",
        "# 7、可视化训练集和验证集的损失函数和准确率\n",
        "def matplot_acc_loss(train_process):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_process['epoch'], train_process.train_loss_all, \"ro-\", label=\"Train loss\")\n",
        "    plt.plot(train_process['epoch'], train_process.val_loss_all, \"bs-\", label=\"Val loss\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_process['epoch'], train_process.train_acc_all, \"ro-\", label=\"Train acc\")\n",
        "    plt.plot(train_process['epoch'], train_process.val_acc_all, \"bs-\", label=\"Val acc\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"acc\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 8、模型开始训练\n",
        "if __name__ == '__main__':\n",
        "    model = EEGNet()\n",
        "    import pdb; pdb.set_trace()\n",
        "    train_loader, val_loader = create_simple_dataloaders()\n",
        "    train_process = train_model_process(model, train_loader, val_loader, num_epochs=500)\n",
        "    matplot_acc_loss(train_process)\n",
        "\n"
      ],
      "metadata": {
        "id": "aN-b-UvU3Y7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **model_test.py**"
      ],
      "metadata": {
        "id": "U02guqzH4SWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的库\n",
        "import mne\n",
        "import scipy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "#from model import EEGNet\n",
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "\n",
        "# 1、创建必要的本地目录，用于保存数据\n",
        "if not os.path.exists('2a_test_pre'):\n",
        "    os.makedirs('2a_test_pre')\n",
        "\n",
        "# 2、原始数据读取和通道重命名\n",
        "data_path = ['A0'+str(i)+'E' for i in range(1, 10)]\n",
        "raw = [mne.io.read_raw_gdf(input_fname='./'+path+'.gdf',\n",
        "                           stim_channel=\"auto\",\n",
        "                           preload=True,\n",
        "                           verbose='error') for path in data_path]\n",
        "\n",
        "for i in range(len(raw)):\n",
        "    raw[i].rename_channels({'EEG-Fz': 'Fz', 'EEG-0': 'FC3', 'EEG-1': 'FC1', 'EEG-2': 'FCz', 'EEG-3': 'FC2',\n",
        "                            'EEG-4': 'FC4', 'EEG-5': 'C5', 'EEG-C3': 'C3', 'EEG-6': 'C1', 'EEG-Cz': 'Cz',\n",
        "                            'EEG-7': 'C2', 'EEG-C4': 'C4', 'EEG-8': 'C6', 'EEG-9': 'CP3', 'EEG-10': 'CP1',\n",
        "                            'EEG-11': 'CPz', 'EEG-12': 'CP2', 'EEG-13': 'CP4', 'EEG-14': 'P1', 'EEG-15': 'Pz',\n",
        "                            'EEG-16': 'P2', 'EEG-Pz': 'POz'})\n",
        "\n",
        "# 3、提取MI时间，完成坏值清洗，并封装\n",
        "events = []\n",
        "for i in range(len(raw)):\n",
        "    event, event_dict = mne.events_from_annotations(raw[i])\n",
        "    events.append(event)\n",
        "\n",
        "    # 打印事件信息用于调试\n",
        "    print(f\"文件 {data_path[i]} 的事件类型: {event_dict}\")\n",
        "\n",
        "    raw[i].load_data()\n",
        "    data = raw[i].get_data()\n",
        "    for i_chan in range(data.shape[0]):\n",
        "        chan = data[i_chan]\n",
        "        data[i_chan] = np.where(chan == np.min(chan), np.nan, chan)\n",
        "        mask = np.isnan(data[i_chan])\n",
        "        chan_mean = np.nanmean(data[i_chan])\n",
        "        data[i_chan, mask] = chan_mean\n",
        "    raw[i] = mne.io.RawArray(data, raw[i].info, verbose=\"error\")\n",
        "\n",
        "# 4、切段、去EOG、做标准化，封存数据为npz\n",
        "tmin, tmax = 0, 4\n",
        "for i in range(len(raw)):\n",
        "    # 对于测试数据，使用768事件（cue开始）来创建epochs\n",
        "    # 在测试数据中，768事件对应MI任务的开始\n",
        "    event_id_test = {'768': 6}  # 使用768事件\n",
        "\n",
        "    try:\n",
        "        epochs = mne.Epochs(raw[i], events[i], event_id=event_id_test, tmin=tmin, tmax=tmax,\n",
        "                           proj=False, baseline=None, preload=True)\n",
        "    except Exception as e:\n",
        "        print(f\"创建epochs失败: {e}\")\n",
        "        print(f\"事件类型: {np.unique(events[i][:, 2])}\")\n",
        "        continue\n",
        "\n",
        "    exclude = [\"EOG-left\", \"EOG-central\", \"EOG-right\"]\n",
        "    epochs.drop_channels(exclude)\n",
        "\n",
        "    labels_file = scipy.io.loadmat('./'+data_path[i]+'.mat')\n",
        "\n",
        "    # 检查测试数据中是否有classlabel\n",
        "    if 'classlabel' in labels_file:\n",
        "        labels = labels_file['classlabel'].reshape(-1)\n",
        "        print(f\"文件 {data_path[i]} 使用classlabel，标签分布: {np.unique(labels, return_counts=True)}\")\n",
        "    else:\n",
        "        # 对于测试数据，我们需要从其他来源获取标签\n",
        "        print(f\"文件 {data_path[i]} 没有classlabel，需要从其他来源获取标签\")\n",
        "\n",
        "        # 方法1: 检查是否有true_labels\n",
        "        if 'true_labels' in labels_file:\n",
        "            labels = labels_file['true_labels'].reshape(-1)\n",
        "            print(f\"使用true_labels，标签分布: {np.unique(labels, return_counts=True)}\")\n",
        "        # 方法2: 检查是否有其他标签字段\n",
        "        elif 'label' in labels_file:\n",
        "            labels = labels_file['label'].reshape(-1)\n",
        "            print(f\"使用label，标签分布: {np.unique(labels, return_counts=True)}\")\n",
        "        else:\n",
        "            # 方法3: 对于真正的测试数据，我们可能需要使用伪标签或从其他文件获取\n",
        "            print(f\"警告: 无法找到标签信息，使用均衡伪标签\")\n",
        "            # 创建均衡的伪标签 (1,2,3,4)\n",
        "            n_epochs = len(epochs)\n",
        "            labels = np.array([1, 2, 3, 4] * (n_epochs // 4 + 1))[:n_epochs]\n",
        "            print(f\"使用伪标签，标签分布: {np.unique(labels, return_counts=True)}\")\n",
        "\n",
        "    epochs_data = epochs.get_data(copy=True)\n",
        "\n",
        "    # 检查是否需要调整时间点\n",
        "    if epochs_data.shape[2] > 1000:\n",
        "        epochs_data = epochs_data[:, :, :1000]  # 取前1000个时间点\n",
        "    elif epochs_data.shape[2] < 1000:\n",
        "        # 如果时间点不足，进行填充\n",
        "        padded_data = np.zeros((epochs_data.shape[0], epochs_data.shape[1], 1000))\n",
        "        padded_data[:, :, :epochs_data.shape[2]] = epochs_data\n",
        "        epochs_data = padded_data\n",
        "\n",
        "    n_samples, n_channels, n_timepoints = epochs_data.shape\n",
        "    epochs_data_flat = epochs_data.reshape(n_samples, -1)\n",
        "\n",
        "    scaler = StandardScaler().fit(epochs_data_flat)\n",
        "    data_scaled = scaler.transform(epochs_data_flat)\n",
        "\n",
        "    data_scaled = data_scaled.reshape(n_samples, n_channels, n_timepoints)\n",
        "\n",
        "    # 确保数据和标签的数量一致\n",
        "    min_length = min(len(data_scaled), len(labels))\n",
        "    data_scaled = data_scaled[:min_length]\n",
        "    labels = labels[:min_length]\n",
        "\n",
        "    print(f\"文件 {data_path[i]}: 数据形状 {data_scaled.shape}, 标签形状 {labels.shape}\")\n",
        "\n",
        "    np.savez('2a_test_pre/'+data_path[i]+'.npz', data=data_scaled, label=labels)\n",
        "\n",
        "\n",
        "# 5、创建测试集数据加载器\n",
        "def create_simple_dataloaders():\n",
        "    # 加载数据\n",
        "    x_test, y_test = [], []\n",
        "    for i in range(1, 10):\n",
        "        try:\n",
        "            test_data = np.load(f'2a_test_pre/A0{i}E.npz')\n",
        "            x_test.append(test_data['data'])\n",
        "            y_test.append(test_data['label'])\n",
        "            print(f\"加载 A0{i}E.npz: 数据形状 {test_data['data'].shape}, 标签形状 {test_data['label'].shape}\")\n",
        "            print(f\"标签分布: {np.unique(test_data['label'], return_counts=True)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"加载 A0{i}E.npz 时出错: {e}\")\n",
        "            continue\n",
        "\n",
        "    # 检查是否成功加载了数据\n",
        "    if len(x_test) == 0:\n",
        "        raise ValueError(\"没有成功加载任何测试数据\")\n",
        "\n",
        "    # 合并数据\n",
        "    x_test = np.concatenate(x_test)\n",
        "    y_test = np.concatenate(y_test)\n",
        "\n",
        "    print(f\"合并后 - 数据形状: {x_test.shape}, 标签形状: {y_test.shape}\")\n",
        "    print(f\"合并后标签分布: {np.unique(y_test, return_counts=True)}\")\n",
        "\n",
        "    # 转换为PyTorch张量\n",
        "    x_test = torch.FloatTensor(x_test).unsqueeze(1)\n",
        "    y_test = torch.LongTensor(y_test - 1)  # 标签从1-4转换为0-3\n",
        "\n",
        "    print(f\"转换后标签范围: {torch.unique(y_test)}\")\n",
        "\n",
        "    # 创建DataLoader\n",
        "    test_loader = DataLoader(\n",
        "        TensorDataset(x_test, y_test),\n",
        "        batch_size=32,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return test_loader\n",
        "\n",
        "\n",
        "# 6、模型测试\n",
        "def test_model_process(model, test_loader):\n",
        "    # 设定测试所用到的设备，有GPU用GPU没有GPU用CPU\n",
        "    device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"使用设备: {device}\")\n",
        "\n",
        "    # 将模型放入到训练设备中\n",
        "    model = model.to(device)\n",
        "\n",
        "    # 打印模型结构\n",
        "    print(\"模型结构:\")\n",
        "    print(model)\n",
        "\n",
        "    # 初始化参数\n",
        "    test_corrects = 0.0\n",
        "    test_num = 0\n",
        "\n",
        "    # 存储预测结果用于分析\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    # 只进行前向传播计算，不计算梯度，从而节省内存，加快运行速度\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (test_data_x, test_data_y) in enumerate(test_loader):\n",
        "            # 将特征放入到测试设备中\n",
        "            test_data_x = test_data_x.to(device)\n",
        "            # 将标签放入到测试设备中\n",
        "            test_data_y = test_data_y.to(device)\n",
        "            # 设置模型为评估模式\n",
        "            model.eval()\n",
        "            # 前向传播过程，输入为测试数据集，输出为对每个样本的预测值\n",
        "            output = model(test_data_x)\n",
        "\n",
        "            # 打印第一个batch的输出用于调试\n",
        "            if batch_idx == 0:\n",
        "                print(f\"模型输出形状: {output.shape}\")\n",
        "                print(f\"前5个样本的输出: {output[:5]}\")\n",
        "                print(f\"前5个样本的softmax概率: {torch.softmax(output[:5], dim=1)}\")\n",
        "\n",
        "            # 查找每一行中最大值对应的行标\n",
        "            pre_lab = torch.argmax(output, dim=1)\n",
        "\n",
        "            # 存储预测结果和真实标签\n",
        "            all_predictions.extend(pre_lab.cpu().numpy())\n",
        "            all_labels.extend(test_data_y.cpu().numpy())\n",
        "\n",
        "            # 如果预测正确，则准确度test_corrects加1\n",
        "            test_corrects += torch.sum(pre_lab == test_data_y.data)\n",
        "            # 将所有的测试样本进行累加\n",
        "            test_num += test_data_x.size(0)\n",
        "\n",
        "            # 打印第一个batch的预测结果\n",
        "            if batch_idx == 0:\n",
        "                print(f\"第一个batch的预测: {pre_lab[:10]}\")\n",
        "                print(f\"第一个batch的真实标签: {test_data_y[:10]}\")\n",
        "                print(f\"第一个batch的正确数量: {torch.sum(pre_lab == test_data_y.data)}\")\n",
        "\n",
        "    # 计算测试准确率\n",
        "    test_acc = test_corrects.double().item() / test_num\n",
        "\n",
        "    # 分析预测结果\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    print(f\"\\n预测结果分析:\")\n",
        "    print(f\"预测标签分布: {np.unique(all_predictions, return_counts=True)}\")\n",
        "    print(f\"真实标签分布: {np.unique(all_labels, return_counts=True)}\")\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "    print(f\"\\n混淆矩阵:\")\n",
        "    print(confusion_matrix(all_labels, all_predictions))\n",
        "    print(f\"\\n分类报告:\")\n",
        "    print(classification_report(all_labels, all_predictions))\n",
        "\n",
        "    print(f\"\\n测试的准确率为: {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "# 7、模型开始测试\n",
        "if __name__ == \"__main__\":\n",
        "    # 检查模型文件是否存在\n",
        "    if not os.path.exists('best_model.pth'):\n",
        "        print(\"错误: 找不到模型文件 'best_model.pth'\")\n",
        "        print(\"请确保模型文件存在于当前目录\")\n",
        "        exit(1)\n",
        "\n",
        "    print(\"加载模型...\")\n",
        "    model = EEGNet()\n",
        "\n",
        "    try:\n",
        "        # 尝试使用weights_only=True加载\n",
        "        model.load_state_dict(torch.load('best_model.pth', weights_only=True))\n",
        "        print(\"模型加载成功 (weights_only=True)\")\n",
        "    except:\n",
        "        try:\n",
        "            # 如果失败，尝试使用weights_only=False\n",
        "            model.load_state_dict(torch.load('best_model.pth', weights_only=False))\n",
        "            print(\"模型加载成功 (weights_only=False)\")\n",
        "        except Exception as e:\n",
        "            print(f\"模型加载失败: {e}\")\n",
        "            exit(1)\n",
        "\n",
        "    print(\"创建数据加载器...\")\n",
        "    test_loader = create_simple_dataloaders()\n",
        "\n",
        "    print(\"开始测试...\")\n",
        "    test_model_process(model, test_loader)"
      ],
      "metadata": {
        "id": "OqfBuPsq3p2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}